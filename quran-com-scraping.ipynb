{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6776841c",
   "metadata": {
    "papermill": {
     "duration": 0.00507,
     "end_time": "2026-02-12T15:57:30.495931",
     "exception": false,
     "start_time": "2026-02-12T15:57:30.490861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Quranic Corpus Web Scraper \n",
    "\n",
    "This notebook scrapes all occurrences of \"Allah\" from the Quranic Arabic Corpus website.\n",
    "\n",
    "**Data source:** https://corpus.quran.com/search.jsp?q=lem%3A%7Bll%7Eah+pos%3Apn\n",
    "\n",
    "**Total results:** Exactly 2,699 UNIQUE occurrences (no duplicates)\n",
    "\n",
    "## Error handling:\n",
    "**DUPLICATES ARE REJECTED, NOT CLEANED**\n",
    "- During scraping: If a location is seen twice, the second one is REJECTED immediately\n",
    "- No duplicate ever enters the dataset\n",
    "- Validation confirms zero duplicates exist\n",
    "- Report shows how many duplicates were rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3c1f3",
   "metadata": {
    "papermill": {
     "duration": 0.004011,
     "end_time": "2026-02-12T15:57:30.505739",
     "exception": false,
     "start_time": "2026-02-12T15:57:30.501728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd54b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:30.516158Z",
     "iopub.status.busy": "2026-02-12T15:57:30.515050Z",
     "iopub.status.idle": "2026-02-12T15:57:36.747140Z",
     "shell.execute_reply": "2026-02-12T15:57:36.745880Z"
    },
    "papermill": {
     "duration": 6.240101,
     "end_time": "2026-02-12T15:57:36.749726",
     "exception": false,
     "start_time": "2026-02-12T15:57:30.509625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0rc2)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89bce0",
   "metadata": {
    "papermill": {
     "duration": 0.004158,
     "end_time": "2026-02-12T15:57:36.758230",
     "exception": false,
     "start_time": "2026-02-12T15:57:36.754072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f40ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:36.769972Z",
     "iopub.status.busy": "2026-02-12T15:57:36.768767Z",
     "iopub.status.idle": "2026-02-12T15:57:38.474946Z",
     "shell.execute_reply": "2026-02-12T15:57:38.473910Z"
    },
    "papermill": {
     "duration": 1.714369,
     "end_time": "2026-02-12T15:57:38.477118",
     "exception": false,
     "start_time": "2026-02-12T15:57:36.762749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186b159",
   "metadata": {
    "papermill": {
     "duration": 0.004776,
     "end_time": "2026-02-12T15:57:38.486248",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.481472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Define Scraping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb165ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:38.496942Z",
     "iopub.status.busy": "2026-02-12T15:57:38.496387Z",
     "iopub.status.idle": "2026-02-12T15:57:38.509045Z",
     "shell.execute_reply": "2026-02-12T15:57:38.507833Z"
    },
    "papermill": {
     "duration": 0.020642,
     "end_time": "2026-02-12T15:57:38.511202",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.490560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_page(page_num, verbose=True):\n",
    "    \"\"\"\n",
    "    Scrape a single page of results from the Quranic corpus.\n",
    "    \n",
    "    Returns all results found on the page (duplicates handled by caller).\n",
    "    \"\"\"\n",
    "    url = f\"https://corpus.quran.com/search.jsp?q=lem%3A%7Bll%7Eah+pos%3Apn&s=1&page={page_num}\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Scraping page {page_num}...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        if verbose:\n",
    "            print(\"âœ“\")\n",
    "    except requests.RequestException as e:\n",
    "        if verbose:\n",
    "            print(f\"âœ— Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    results = []\n",
    "    rows = soup.find_all('tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        c1 = row.find('td', class_='c1')\n",
    "        c2 = row.find('td', class_='c2')\n",
    "        c3 = row.find('td', class_='c3')\n",
    "        \n",
    "        if c1 and c2 and c3:\n",
    "            location_span = c1.find('span', class_='l')\n",
    "            if not location_span:\n",
    "                continue\n",
    "                \n",
    "            location_text = location_span.get_text(strip=True)\n",
    "            \n",
    "            if not (location_text.startswith('(') and location_text.endswith(')')):\n",
    "                continue\n",
    "                \n",
    "            location = location_text.strip('()')\n",
    "            \n",
    "            # Validate location format\n",
    "            match = re.match(r'^(\\d+):(\\d+):(\\d+)$', location)\n",
    "            if not match:\n",
    "                continue\n",
    "            \n",
    "            chapter = match.group(1)\n",
    "            verse = match.group(2)\n",
    "            word_position = match.group(3)\n",
    "            \n",
    "            transliteration_tag = c1.find('i', class_='ab')\n",
    "            transliteration = transliteration_tag.get_text(strip=True) if transliteration_tag else \"\"\n",
    "            \n",
    "            if not transliteration:\n",
    "                continue\n",
    "            \n",
    "            translation_link = c2.find('a')\n",
    "            translation = translation_link.get_text(strip=True) if translation_link else c2.get_text(strip=True)\n",
    "            \n",
    "            arabic_text = c3.get_text(strip=True)\n",
    "            \n",
    "            if not arabic_text:\n",
    "                continue\n",
    "            \n",
    "            results.append({\n",
    "                'location': location,\n",
    "                'chapter': chapter,\n",
    "                'verse': verse,\n",
    "                'word_position': word_position,\n",
    "                'transliteration': transliteration,\n",
    "                'translation': translation,\n",
    "                'arabic_verse': arabic_text\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a7b23",
   "metadata": {
    "papermill": {
     "duration": 0.004325,
     "end_time": "2026-02-12T15:57:38.519994",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.515669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Main Scraping Function - REJECTS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250ebad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:38.532683Z",
     "iopub.status.busy": "2026-02-12T15:57:38.532018Z",
     "iopub.status.idle": "2026-02-12T15:57:38.542246Z",
     "shell.execute_reply": "2026-02-12T15:57:38.541192Z"
    },
    "papermill": {
     "duration": 0.020311,
     "end_time": "2026-02-12T15:57:38.544513",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.524202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_all_pages(total_pages=54):\n",
    "    \"\"\"\n",
    "    Scrape all pages and REJECT duplicates immediately.\n",
    "    \n",
    "    CRITICAL: Duplicates are NEVER added to the results list.\n",
    "    They are counted and reported, but REJECTED.\n",
    "    \"\"\"\n",
    "    unique_results = []  # Only unique entries go here\n",
    "    seen_locations = set()  # Track what we've already added\n",
    "    \n",
    "    # Track duplicate encounters for reporting\n",
    "    duplicate_locations = []\n",
    "    \n",
    "    print(f\"Starting scrape of {total_pages} pages...\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DUPLICATE POLICY: Reject on sight - never add to dataset\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for page in range(1, total_pages + 1):\n",
    "        page_results = scrape_page(page)\n",
    "        \n",
    "        # Process each result\n",
    "        for result in page_results:\n",
    "            loc = result['location']\n",
    "            \n",
    "            if loc not in seen_locations:\n",
    "                # First time seeing this - ADD IT\n",
    "                seen_locations.add(loc)\n",
    "                unique_results.append(result)\n",
    "            else:\n",
    "                # Already seen - REJECT IT\n",
    "                duplicate_locations.append({\n",
    "                    'location': loc,\n",
    "                    'page': page,\n",
    "                    'rejected': True\n",
    "                })\n",
    "        \n",
    "        if page % 10 == 0:\n",
    "            print(f\"Progress: {page}/{total_pages} pages | Unique: {len(unique_results)} | Rejected: {len(duplicate_locations)}\")\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nâœ“ SCRAPING COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Unique entries collected: {len(unique_results)}\")\n",
    "    print(f\"Duplicate entries REJECTED: {len(duplicate_locations)}\")\n",
    "    print(f\"Expected unique entries: 2699\")\n",
    "    print(f\"Difference: {len(unique_results) - 2699:+d}\")\n",
    "    \n",
    "    # Report duplicates if found\n",
    "    if duplicate_locations:\n",
    "        print(f\"\\nâš ï¸  {len(duplicate_locations)} DUPLICATES WERE REJECTED:\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, dup in enumerate(duplicate_locations[:20], 1):  # Show first 20\n",
    "            print(f\"  {i}. Location {dup['location']} (rejected on page {dup['page']})\")\n",
    "        if len(duplicate_locations) > 20:\n",
    "            print(f\"  ... and {len(duplicate_locations) - 20} more\")\n",
    "        print(\"-\" * 60)\n",
    "        print(\"These duplicates were NOT added to the dataset.\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ NO DUPLICATES ENCOUNTERED\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return unique_results, duplicate_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78d735",
   "metadata": {
    "papermill": {
     "duration": 0.004755,
     "end_time": "2026-02-12T15:57:38.553683",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.548928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Validation Function - Verify Zero Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c1a7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:38.564347Z",
     "iopub.status.busy": "2026-02-12T15:57:38.563987Z",
     "iopub.status.idle": "2026-02-12T15:57:38.571519Z",
     "shell.execute_reply": "2026-02-12T15:57:38.570375Z"
    },
    "papermill": {
     "duration": 0.015479,
     "end_time": "2026-02-12T15:57:38.573553",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.558074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_no_duplicates(df):\n",
    "    \"\"\"\n",
    "    Validate that the DataFrame has ZERO duplicates.\n",
    "    This should always pass if scraping worked correctly.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"VALIDATION: Checking for duplicates in final dataset\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check for duplicate locations\n",
    "    location_counts = df['location'].value_counts()\n",
    "    duplicates = location_counts[location_counts > 1]\n",
    "    \n",
    "    if len(duplicates) == 0:\n",
    "        print(\"âœ“ VALIDATION PASSED: Zero duplicates found\")\n",
    "        print(f\"  All {len(df)} entries have unique locations\")\n",
    "        print(\"  Dataset is clean and ready for analysis\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"âœ— VALIDATION FAILED: Duplicates found in dataset!\")\n",
    "        print(f\"  {len(duplicates)} locations appear multiple times\")\n",
    "        print(\"\\nThis should not happen. Duplicate locations:\")\n",
    "        for loc, count in duplicates.items():\n",
    "            print(f\"  {loc}: {count} times\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f52986",
   "metadata": {
    "papermill": {
     "duration": 0.004151,
     "end_time": "2026-02-12T15:57:38.582186",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.578035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Test with First 3 Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074f6dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:38.595227Z",
     "iopub.status.busy": "2026-02-12T15:57:38.593790Z",
     "iopub.status.idle": "2026-02-12T15:57:41.911177Z",
     "shell.execute_reply": "2026-02-12T15:57:41.910165Z"
    },
    "papermill": {
     "duration": 3.325833,
     "end_time": "2026-02-12T15:57:41.913061",
     "exception": false,
     "start_time": "2026-02-12T15:57:38.587228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with first 3 pages...\n",
      "\n",
      "Starting scrape of 3 pages...\n",
      "============================================================\n",
      "DUPLICATE POLICY: Reject on sight - never add to dataset\n",
      "============================================================\n",
      "Scraping page 1... âœ“\n",
      "Scraping page 2... âœ“\n",
      "Scraping page 3... âœ“\n",
      "============================================================\n",
      "\n",
      "âœ“ SCRAPING COMPLETE\n",
      "============================================================\n",
      "Unique entries collected: 150\n",
      "Duplicate entries REJECTED: 3\n",
      "Expected unique entries: 2699\n",
      "Difference: -2549\n",
      "\n",
      "âš ï¸  3 DUPLICATES WERE REJECTED:\n",
      "------------------------------------------------------------\n",
      "  1. Location 1:1:2 (rejected on page 1)\n",
      "  2. Location 2:97:11 (rejected on page 2)\n",
      "  3. Location 2:161:10 (rejected on page 3)\n",
      "------------------------------------------------------------\n",
      "These duplicates were NOT added to the dataset.\n",
      "============================================================\n",
      "\n",
      "Expected approximately: 150 results\n",
      "Actual unique results: 150\n",
      "\n",
      "============================================================\n",
      "VALIDATION: Checking for duplicates in final dataset\n",
      "============================================================\n",
      "âœ“ VALIDATION PASSED: Zero duplicates found\n",
      "  All 150 entries have unique locations\n",
      "  Dataset is clean and ready for analysis\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>word_position</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>translation</th>\n",
       "      <th>arabic_verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:1:2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>(of) Allah</td>\n",
       "      <td>Ø¨ÙØ³Ù’Ù…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ø±Ù‘ÙØ­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:2:2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>lillahi</td>\n",
       "      <td>(be) to Allah</td>\n",
       "      <td>Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯ÙÙ„ÙÙ„Ù‘ÙÙ‡ÙØ±ÙØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2:7:2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø®ÙØªÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ„ÙÙ‰Ù° Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙ…Ù’Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2:8:6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>bil-lahi</td>\n",
       "      <td>in Allah</td>\n",
       "      <td>ÙˆÙÙ…ÙÙ†Ù Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù Ù…ÙÙ†Ù’ ÙŠÙÙ‚ÙÙˆÙ„Ù Ø¢Ù…ÙÙ†Ù‘ÙØ§Ø¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2:9:2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>l-laha</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙŠÙØ®ÙØ§Ø¯ÙØ¹ÙÙˆÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù‘ÙØ°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙÙ…ÙØ§ ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2:10:5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙÙÙŠ Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ Ù…ÙØ±ÙØ¶ÙŒ ÙÙØ²ÙØ§Ø¯ÙÙ‡ÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ±ÙØ¶Ù‹Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2:15:1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>al-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ³Ù’ØªÙÙ‡Ù’Ø²ÙØ¦Ù Ø¨ÙÙ‡ÙÙ…Ù’ ÙˆÙÙŠÙÙ…ÙØ¯Ù‘ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø·...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2:17:11</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙÙÙ„ÙÙ…Ù‘ÙØ§ Ø£ÙØ¶ÙØ§Ø¡ÙØªÙ’ Ù…ÙØ§ Ø­ÙÙˆÙ’Ù„ÙÙ‡Ù Ø°ÙÙ‡ÙØ¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2:19:17</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>wal-lahu</td>\n",
       "      <td>And Allah</td>\n",
       "      <td>ÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ­ÙÙŠØ·ÙŒ Ø¨ÙØ§Ù„Ù’ÙƒÙØ§ÙÙØ±ÙÙŠÙ†Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2:20:16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙˆÙÙ„ÙÙˆÙ’ Ø´ÙØ§Ø¡ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ„ÙØ°ÙÙ‡ÙØ¨Ù Ø¨ÙØ³ÙÙ…Ù’Ø¹ÙÙ‡ÙÙ…Ù’ ÙˆÙØ£ÙØ¨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location chapter verse word_position transliteration    translation  \\\n",
       "0    1:1:2       1     1             2          l-lahi     (of) Allah   \n",
       "1    1:2:2       1     2             2         lillahi  (be) to Allah   \n",
       "2    2:7:2       2     7             2          l-lahu          Allah   \n",
       "3    2:8:6       2     8             6        bil-lahi       in Allah   \n",
       "4    2:9:2       2     9             2          l-laha          Allah   \n",
       "5   2:10:5       2    10             5          l-lahu          Allah   \n",
       "6   2:15:1       2    15             1         al-lahu          Allah   \n",
       "7  2:17:11       2    17            11          l-lahu          Allah   \n",
       "8  2:19:17       2    19            17        wal-lahu      And Allah   \n",
       "9  2:20:16       2    20            16          l-lahu          Allah   \n",
       "\n",
       "                                        arabic_verse  \n",
       "0               Ø¨ÙØ³Ù’Ù…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ø±Ù‘ÙØ­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù  \n",
       "1                Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯ÙÙ„ÙÙ„Ù‘ÙÙ‡ÙØ±ÙØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù  \n",
       "2  Ø®ÙØªÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ„ÙÙ‰Ù° Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙ…Ù’Ø¹...  \n",
       "3  ÙˆÙÙ…ÙÙ†Ù Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù Ù…ÙÙ†Ù’ ÙŠÙÙ‚ÙÙˆÙ„Ù Ø¢Ù…ÙÙ†Ù‘ÙØ§Ø¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆ...  \n",
       "4  ÙŠÙØ®ÙØ§Ø¯ÙØ¹ÙÙˆÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù‘ÙØ°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙÙ…ÙØ§ ÙŠ...  \n",
       "5   ÙÙÙŠ Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ Ù…ÙØ±ÙØ¶ÙŒ ÙÙØ²ÙØ§Ø¯ÙÙ‡ÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ±ÙØ¶Ù‹Ø§  \n",
       "6  Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ³Ù’ØªÙÙ‡Ù’Ø²ÙØ¦Ù Ø¨ÙÙ‡ÙÙ…Ù’ ÙˆÙÙŠÙÙ…ÙØ¯Ù‘ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø·...  \n",
       "7  ÙÙÙ„ÙÙ…Ù‘ÙØ§ Ø£ÙØ¶ÙØ§Ø¡ÙØªÙ’ Ù…ÙØ§ Ø­ÙÙˆÙ’Ù„ÙÙ‡Ù Ø°ÙÙ‡ÙØ¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨...  \n",
       "8                   ÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ­ÙÙŠØ·ÙŒ Ø¨ÙØ§Ù„Ù’ÙƒÙØ§ÙÙØ±ÙÙŠÙ†Ù  \n",
       "9  ÙˆÙÙ„ÙÙˆÙ’ Ø´ÙØ§Ø¡ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ„ÙØ°ÙÙ‡ÙØ¨Ù Ø¨ÙØ³ÙÙ…Ù’Ø¹ÙÙ‡ÙÙ…Ù’ ÙˆÙØ£ÙØ¨...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Testing with first 3 pages...\\n\")\n",
    "test_results, test_duplicates = scrape_all_pages(total_pages=3)\n",
    "\n",
    "expected_per_page = 2699 / 54\n",
    "expected_for_3 = expected_per_page * 3\n",
    "\n",
    "print(f\"\\nExpected approximately: {expected_for_3:.0f} results\")\n",
    "print(f\"Actual unique results: {len(test_results)}\")\n",
    "\n",
    "if len(test_results) > 0:\n",
    "    df_test = pd.DataFrame(test_results)\n",
    "    validate_no_duplicates(df_test)\n",
    "    \n",
    "    print(\"\\nSample data:\")\n",
    "    display(df_test.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a342b049",
   "metadata": {
    "papermill": {
     "duration": 0.005729,
     "end_time": "2026-02-12T15:57:41.924057",
     "exception": false,
     "start_time": "2026-02-12T15:57:41.918328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Scrape All 54 Pages (Full Dataset)\n",
    "\n",
    "**Warning:** This will take approximately 30-45 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a911205c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:57:41.936453Z",
     "iopub.status.busy": "2026-02-12T15:57:41.936110Z",
     "iopub.status.idle": "2026-02-12T15:58:34.238847Z",
     "shell.execute_reply": "2026-02-12T15:58:34.237707Z"
    },
    "papermill": {
     "duration": 52.311186,
     "end_time": "2026-02-12T15:58:34.240833",
     "exception": false,
     "start_time": "2026-02-12T15:57:41.929647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scrape of 54 pages...\n",
      "============================================================\n",
      "DUPLICATE POLICY: Reject on sight - never add to dataset\n",
      "============================================================\n",
      "Scraping page 1... âœ“\n",
      "Scraping page 2... âœ“\n",
      "Scraping page 3... âœ“\n",
      "Scraping page 4... âœ“\n",
      "Scraping page 5... âœ“\n",
      "Scraping page 6... âœ“\n",
      "Scraping page 7... âœ“\n",
      "Scraping page 8... âœ“\n",
      "Scraping page 9... âœ“\n",
      "Scraping page 10... âœ“\n",
      "Progress: 10/54 pages | Unique: 500 | Rejected: 10\n",
      "Scraping page 11... âœ“\n",
      "Scraping page 12... âœ“\n",
      "Scraping page 13... âœ“\n",
      "Scraping page 14... âœ“\n",
      "Scraping page 15... âœ“\n",
      "Scraping page 16... âœ“\n",
      "Scraping page 17... âœ“\n",
      "Scraping page 18... âœ“\n",
      "Scraping page 19... âœ“\n",
      "Scraping page 20... âœ“\n",
      "Progress: 20/54 pages | Unique: 1000 | Rejected: 20\n",
      "Scraping page 21... âœ“\n",
      "Scraping page 22... âœ“\n",
      "Scraping page 23... âœ“\n",
      "Scraping page 24... âœ“\n",
      "Scraping page 25... âœ“\n",
      "Scraping page 26... âœ“\n",
      "Scraping page 27... âœ“\n",
      "Scraping page 28... âœ“\n",
      "Scraping page 29... âœ“\n",
      "Scraping page 30... âœ“\n",
      "Progress: 30/54 pages | Unique: 1500 | Rejected: 30\n",
      "Scraping page 31... âœ“\n",
      "Scraping page 32... âœ“\n",
      "Scraping page 33... âœ“\n",
      "Scraping page 34... âœ“\n",
      "Scraping page 35... âœ“\n",
      "Scraping page 36... âœ“\n",
      "Scraping page 37... âœ“\n",
      "Scraping page 38... âœ“\n",
      "Scraping page 39... âœ“\n",
      "Scraping page 40... âœ“\n",
      "Progress: 40/54 pages | Unique: 2000 | Rejected: 40\n",
      "Scraping page 41... âœ“\n",
      "Scraping page 42... âœ“\n",
      "Scraping page 43... âœ“\n",
      "Scraping page 44... âœ“\n",
      "Scraping page 45... âœ“\n",
      "Scraping page 46... âœ“\n",
      "Scraping page 47... âœ“\n",
      "Scraping page 48... âœ“\n",
      "Scraping page 49... âœ“\n",
      "Scraping page 50... âœ“\n",
      "Progress: 50/54 pages | Unique: 2500 | Rejected: 50\n",
      "Scraping page 51... âœ“\n",
      "Scraping page 52... âœ“\n",
      "Scraping page 53... âœ“\n",
      "Scraping page 54... âœ“\n",
      "============================================================\n",
      "\n",
      "âœ“ SCRAPING COMPLETE\n",
      "============================================================\n",
      "Unique entries collected: 2699\n",
      "Duplicate entries REJECTED: 54\n",
      "Expected unique entries: 2699\n",
      "Difference: +0\n",
      "\n",
      "âš ï¸  54 DUPLICATES WERE REJECTED:\n",
      "------------------------------------------------------------\n",
      "  1. Location 1:1:2 (rejected on page 1)\n",
      "  2. Location 2:97:11 (rejected on page 2)\n",
      "  3. Location 2:161:10 (rejected on page 3)\n",
      "  4. Location 2:209:10 (rejected on page 4)\n",
      "  5. Location 2:235:15 (rejected on page 5)\n",
      "  6. Location 2:264:16 (rejected on page 6)\n",
      "  7. Location 3:19:22 (rejected on page 7)\n",
      "  8. Location 3:73:11 (rejected on page 8)\n",
      "  9. Location 3:120:18 (rejected on page 9)\n",
      "  10. Location 3:163:4 (rejected on page 10)\n",
      "  11. Location 4:11:68 (rejected on page 11)\n",
      "  12. Location 4:50:5 (rejected on page 12)\n",
      "  13. Location 4:90:33 (rejected on page 13)\n",
      "  14. Location 4:127:5 (rejected on page 14)\n",
      "  15. Location 4:162:20 (rejected on page 15)\n",
      "  16. Location 5:17:6 (rejected on page 16)\n",
      "  17. Location 5:57:20 (rejected on page 17)\n",
      "  18. Location 5:103:3 (rejected on page 18)\n",
      "  19. Location 6:71:5 (rejected on page 19)\n",
      "  20. Location 6:151:35 (rejected on page 20)\n",
      "  ... and 34 more\n",
      "------------------------------------------------------------\n",
      "These duplicates were NOT added to the dataset.\n",
      "============================================================\n",
      "\n",
      "Final DataFrame shape: (2699, 7)\n",
      "Columns: ['location', 'chapter', 'verse', 'word_position', 'transliteration', 'translation', 'arabic_verse']\n"
     ]
    }
   ],
   "source": [
    "# Scrape all pages\n",
    "all_results, rejected_duplicates = scrape_all_pages(total_pages=54)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "print(f\"\\nFinal DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85750a9c",
   "metadata": {
    "papermill": {
     "duration": 0.00971,
     "end_time": "2026-02-12T15:58:34.261267",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.251557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Final Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b831170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:58:34.283100Z",
     "iopub.status.busy": "2026-02-12T15:58:34.282264Z",
     "iopub.status.idle": "2026-02-12T15:58:34.291284Z",
     "shell.execute_reply": "2026-02-12T15:58:34.290167Z"
    },
    "papermill": {
     "duration": 0.022489,
     "end_time": "2026-02-12T15:58:34.293419",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.270930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION: Checking for duplicates in final dataset\n",
      "============================================================\n",
      "âœ“ VALIDATION PASSED: Zero duplicates found\n",
      "  All 2699 entries have unique locations\n",
      "  Dataset is clean and ready for analysis\n",
      "\n",
      "âœ“ Dataset ready for export\n"
     ]
    }
   ],
   "source": [
    "# Validate the final dataset\n",
    "validation_passed = validate_no_duplicates(df)\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"\\nâœ“ Dataset ready for export\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Dataset has issues - review above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a45ce",
   "metadata": {
    "papermill": {
     "duration": 0.009559,
     "end_time": "2026-02-12T15:58:34.312718",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.303159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab2fd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:58:34.333533Z",
     "iopub.status.busy": "2026-02-12T15:58:34.333194Z",
     "iopub.status.idle": "2026-02-12T15:58:34.362939Z",
     "shell.execute_reply": "2026-02-12T15:58:34.361916Z"
    },
    "papermill": {
     "duration": 0.042951,
     "end_time": "2026-02-12T15:58:34.365047",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.322096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FILE SAVED\n",
      "============================================================\n",
      "Filename: allah_occurrences_NO_DUPLICATES.csv\n",
      "Total rows: 2699\n",
      "File size: 420.2 KB\n",
      "Duplicates in file: 0 (guaranteed)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    csv_filename = 'allah_occurrences_NO_DUPLICATES.csv'\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"FILE SAVED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Filename: {csv_filename}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"File size: {os.path.getsize(csv_filename) / 1024:.1f} KB\")\n",
    "    print(f\"Duplicates in file: 0 (guaranteed)\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"âš ï¸  No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca835f3",
   "metadata": {
    "papermill": {
     "duration": 0.009346,
     "end_time": "2026-02-12T15:58:34.383981",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.374635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Export Rejected Duplicates Report (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e65602d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:58:34.404653Z",
     "iopub.status.busy": "2026-02-12T15:58:34.404298Z",
     "iopub.status.idle": "2026-02-12T15:58:34.417259Z",
     "shell.execute_reply": "2026-02-12T15:58:34.416434Z"
    },
    "papermill": {
     "duration": 0.025761,
     "end_time": "2026-02-12T15:58:34.419142",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.393381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Rejected duplicates report saved: rejected_duplicates_report.csv\n",
      "   Total rejected: 54\n",
      "\n",
      "First 10 rejected entries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>page</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:1:2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2:97:11</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2:161:10</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2:209:10</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2:235:15</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2:264:16</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3:19:22</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3:73:11</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3:120:18</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3:163:4</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  page  rejected\n",
       "0     1:1:2     1      True\n",
       "1   2:97:11     2      True\n",
       "2  2:161:10     3      True\n",
       "3  2:209:10     4      True\n",
       "4  2:235:15     5      True\n",
       "5  2:264:16     6      True\n",
       "6   3:19:22     7      True\n",
       "7   3:73:11     8      True\n",
       "8  3:120:18     9      True\n",
       "9   3:163:4    10      True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if rejected_duplicates:\n",
    "    df_rejected = pd.DataFrame(rejected_duplicates)\n",
    "    rejected_filename = 'rejected_duplicates_report.csv'\n",
    "    df_rejected.to_csv(rejected_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Rejected duplicates report saved: {rejected_filename}\")\n",
    "    print(f\"   Total rejected: {len(rejected_duplicates)}\")\n",
    "    print(\"\\nFirst 10 rejected entries:\")\n",
    "    display(df_rejected.head(10))\n",
    "else:\n",
    "    print(\"\\nâœ“ No duplicates were encountered, so no rejection report needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dba062",
   "metadata": {
    "papermill": {
     "duration": 0.009708,
     "end_time": "2026-02-12T15:58:34.438590",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.428882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8716b55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:58:34.459758Z",
     "iopub.status.busy": "2026-02-12T15:58:34.459430Z",
     "iopub.status.idle": "2026-02-12T15:58:34.515046Z",
     "shell.execute_reply": "2026-02-12T15:58:34.513887Z"
    },
    "papermill": {
     "duration": 0.068494,
     "end_time": "2026-02-12T15:58:34.516824",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.448330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "Total unique occurrences: 2699\n",
      "Unique chapters: 85\n",
      "Unique verses: 1821\n",
      "Unique transliterations: 17\n",
      "Duplicates in dataset: 0 (verified)\n",
      "\n",
      "============================================================\n",
      "TOP 10 TRANSLITERATIONS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transliteration\n",
       "l-lahi       827\n",
       "l-lahu       701\n",
       "l-laha       591\n",
       "wal-lahu     239\n",
       "bil-lahi     139\n",
       "lillahi      116\n",
       "al-lahu       32\n",
       "walillahi     27\n",
       "tal-lahi       8\n",
       "fal-lahu       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP 10 CHAPTERS BY FREQUENCY\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "chapter\n",
       "2     282\n",
       "4     229\n",
       "3     209\n",
       "9     169\n",
       "5     147\n",
       "33     90\n",
       "8      88\n",
       "6      87\n",
       "16     84\n",
       "24     80\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATASET STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total unique occurrences: {len(df)}\")\n",
    "    print(f\"Unique chapters: {df['chapter'].nunique()}\")\n",
    "    print(f\"Unique verses: {len(df.groupby(['chapter', 'verse']))}\")\n",
    "    print(f\"Unique transliterations: {df['transliteration'].nunique()}\")\n",
    "    print(f\"Duplicates in dataset: 0 (verified)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TOP 10 TRANSLITERATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    display(df['transliteration'].value_counts().head(10))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TOP 10 CHAPTERS BY FREQUENCY\")\n",
    "    print(\"=\" * 60)\n",
    "    display(df['chapter'].value_counts().head(10))\n",
    "else:\n",
    "    print(\"âš ï¸  No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762e70e",
   "metadata": {
    "papermill": {
     "duration": 0.01109,
     "end_time": "2026-02-12T15:58:34.538198",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.527108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 12. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119c2518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T15:58:34.561389Z",
     "iopub.status.busy": "2026-02-12T15:58:34.561082Z",
     "iopub.status.idle": "2026-02-12T15:58:34.583199Z",
     "shell.execute_reply": "2026-02-12T15:58:34.582279Z"
    },
    "papermill": {
     "duration": 0.036969,
     "end_time": "2026-02-12T15:58:34.585129",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.548160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>word_position</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>translation</th>\n",
       "      <th>arabic_verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:1:2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>(of) Allah</td>\n",
       "      <td>Ø¨ÙØ³Ù’Ù…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ø±Ù‘ÙØ­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:2:2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>lillahi</td>\n",
       "      <td>(be) to Allah</td>\n",
       "      <td>Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯ÙÙ„ÙÙ„Ù‘ÙÙ‡ÙØ±ÙØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2:7:2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø®ÙØªÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ„ÙÙ‰Ù° Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙ…Ù’Ø¹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2:8:6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>bil-lahi</td>\n",
       "      <td>in Allah</td>\n",
       "      <td>ÙˆÙÙ…ÙÙ†Ù Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù Ù…ÙÙ†Ù’ ÙŠÙÙ‚ÙÙˆÙ„Ù Ø¢Ù…ÙÙ†Ù‘ÙØ§Ø¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2:9:2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>l-laha</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙŠÙØ®ÙØ§Ø¯ÙØ¹ÙÙˆÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù‘ÙØ°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙÙ…ÙØ§ ÙŠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2:10:5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙÙÙŠ Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ Ù…ÙØ±ÙØ¶ÙŒ ÙÙØ²ÙØ§Ø¯ÙÙ‡ÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ±ÙØ¶Ù‹Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2:15:1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>al-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ³Ù’ØªÙÙ‡Ù’Ø²ÙØ¦Ù Ø¨ÙÙ‡ÙÙ…Ù’ ÙˆÙÙŠÙÙ…ÙØ¯Ù‘ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø·...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2:17:11</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙÙÙ„ÙÙ…Ù‘ÙØ§ Ø£ÙØ¶ÙØ§Ø¡ÙØªÙ’ Ù…ÙØ§ Ø­ÙÙˆÙ’Ù„ÙÙ‡Ù Ø°ÙÙ‡ÙØ¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2:19:17</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>wal-lahu</td>\n",
       "      <td>And Allah</td>\n",
       "      <td>ÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ­ÙÙŠØ·ÙŒ Ø¨ÙØ§Ù„Ù’ÙƒÙØ§ÙÙØ±ÙÙŠÙ†Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2:20:16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙˆÙÙ„ÙÙˆÙ’ Ø´ÙØ§Ø¡ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ„ÙØ°ÙÙ‡ÙØ¨Ù Ø¨ÙØ³ÙÙ…Ù’Ø¹ÙÙ‡ÙÙ…Ù’ ÙˆÙØ£ÙØ¨...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location chapter verse word_position transliteration    translation  \\\n",
       "0    1:1:2       1     1             2          l-lahi     (of) Allah   \n",
       "1    1:2:2       1     2             2         lillahi  (be) to Allah   \n",
       "2    2:7:2       2     7             2          l-lahu          Allah   \n",
       "3    2:8:6       2     8             6        bil-lahi       in Allah   \n",
       "4    2:9:2       2     9             2          l-laha          Allah   \n",
       "5   2:10:5       2    10             5          l-lahu          Allah   \n",
       "6   2:15:1       2    15             1         al-lahu          Allah   \n",
       "7  2:17:11       2    17            11          l-lahu          Allah   \n",
       "8  2:19:17       2    19            17        wal-lahu      And Allah   \n",
       "9  2:20:16       2    20            16          l-lahu          Allah   \n",
       "\n",
       "                                        arabic_verse  \n",
       "0               Ø¨ÙØ³Ù’Ù…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ø±Ù‘ÙØ­Ù’Ù…ÙÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù  \n",
       "1                Ø§Ù„Ù’Ø­ÙÙ…Ù’Ø¯ÙÙ„ÙÙ„Ù‘ÙÙ‡ÙØ±ÙØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙØ§Ù„ÙÙ…ÙÙŠÙ†Ù  \n",
       "2  Ø®ÙØªÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ„ÙÙ‰Ù° Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ ÙˆÙØ¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙ…Ù’Ø¹...  \n",
       "3  ÙˆÙÙ…ÙÙ†Ù Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù Ù…ÙÙ†Ù’ ÙŠÙÙ‚ÙÙˆÙ„Ù Ø¢Ù…ÙÙ†Ù‘ÙØ§Ø¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆ...  \n",
       "4  ÙŠÙØ®ÙØ§Ø¯ÙØ¹ÙÙˆÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù‘ÙØ°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙÙ…ÙØ§ ÙŠ...  \n",
       "5   ÙÙÙŠ Ù‚ÙÙ„ÙÙˆØ¨ÙÙ‡ÙÙ…Ù’ Ù…ÙØ±ÙØ¶ÙŒ ÙÙØ²ÙØ§Ø¯ÙÙ‡ÙÙ…ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ±ÙØ¶Ù‹Ø§  \n",
       "6  Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ³Ù’ØªÙÙ‡Ù’Ø²ÙØ¦Ù Ø¨ÙÙ‡ÙÙ…Ù’ ÙˆÙÙŠÙÙ…ÙØ¯Ù‘ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø·...  \n",
       "7  ÙÙÙ„ÙÙ…Ù‘ÙØ§ Ø£ÙØ¶ÙØ§Ø¡ÙØªÙ’ Ù…ÙØ§ Ø­ÙÙˆÙ’Ù„ÙÙ‡Ù Ø°ÙÙ‡ÙØ¨ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨...  \n",
       "8                   ÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ­ÙÙŠØ·ÙŒ Ø¨ÙØ§Ù„Ù’ÙƒÙØ§ÙÙØ±ÙÙŠÙ†Ù  \n",
       "9  ÙˆÙÙ„ÙÙˆÙ’ Ø´ÙØ§Ø¡ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙ„ÙØ°ÙÙ‡ÙØ¨Ù Ø¨ÙØ³ÙÙ…Ù’Ø¹ÙÙ‡ÙÙ…Ù’ ÙˆÙØ£ÙØ¨...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>word_position</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>translation</th>\n",
       "      <th>arabic_verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>95:8:2</td>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø£ÙÙ„ÙÙŠÙ’Ø³ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨ÙØ£ÙØ­Ù’ÙƒÙÙ…Ù Ø§Ù„Ù’Ø­ÙØ§ÙƒÙÙ…ÙÙŠÙ†Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>96:14:4</td>\n",
       "      <td>96</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>l-laha</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø£ÙÙ„ÙÙ…Ù’ ÙŠÙØ¹Ù’Ù„ÙÙ…Ù’ Ø¨ÙØ£ÙÙ†Ù‘ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ±ÙÙ‰Ù°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>98:2:3</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø±ÙØ³ÙÙˆÙ„ÙŒ Ù…ÙÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØªÙ’Ù„ÙÙˆ ØµÙØ­ÙÙÙ‹Ø§ Ù…ÙØ·ÙÙ‡Ù‘ÙØ±ÙØ©Ù‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>98:5:5</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>l-laha</td>\n",
       "      <td>Allah</td>\n",
       "      <td>ÙˆÙÙ…ÙØ§ Ø£ÙÙ…ÙØ±ÙÙˆØ§ Ø¥ÙÙ„Ù‘ÙØ§ Ù„ÙÙŠÙØ¹Ù’Ø¨ÙØ¯ÙÙˆØ§Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ®Ù’Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>98:8:14</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø±ÙØ¶ÙÙŠÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ†Ù’Ù‡ÙÙ…Ù’ ÙˆÙØ±ÙØ¶ÙÙˆØ§ Ø¹ÙÙ†Ù’Ù‡Ù Ø°ÙÙ°Ù„ÙÙƒÙ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>104:6:2</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ù†ÙØ§Ø±ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ù’Ù…ÙÙˆÙ‚ÙØ¯ÙØ©Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>110:1:4</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>(of) Allah</td>\n",
       "      <td>Ø¥ÙØ°ÙØ§ Ø¬ÙØ§Ø¡Ù Ù†ÙØµÙ’Ø±ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù’ÙÙØªÙ’Ø­Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>110:2:6</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>l-lahi</td>\n",
       "      <td>(of) Allah</td>\n",
       "      <td>ÙˆÙØ±ÙØ£ÙÙŠÙ’ØªÙ Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù ÙŠÙØ¯Ù’Ø®ÙÙ„ÙÙˆÙ†Ù ÙÙÙŠ Ø¯ÙÙŠÙ†ÙØ§Ù„Ù„Ù‘Ù...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>112:1:3</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>l-lahu</td>\n",
       "      <td>(is) Allah</td>\n",
       "      <td>Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ£ÙØ­ÙØ¯ÙŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>112:2:1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>al-lahu</td>\n",
       "      <td>Allah</td>\n",
       "      <td>Ø§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„ØµÙ‘ÙÙ…ÙØ¯Ù</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location chapter verse word_position transliteration translation  \\\n",
       "2689   95:8:2      95     8             2          l-lahu       Allah   \n",
       "2690  96:14:4      96    14             4          l-laha       Allah   \n",
       "2691   98:2:3      98     2             3          l-lahi       Allah   \n",
       "2692   98:5:5      98     5             5          l-laha       Allah   \n",
       "2693  98:8:14      98     8            14          l-lahu       Allah   \n",
       "2694  104:6:2     104     6             2          l-lahi       Allah   \n",
       "2695  110:1:4     110     1             4          l-lahi  (of) Allah   \n",
       "2696  110:2:6     110     2             6          l-lahi  (of) Allah   \n",
       "2697  112:1:3     112     1             3          l-lahu  (is) Allah   \n",
       "2698  112:2:1     112     2             1         al-lahu       Allah   \n",
       "\n",
       "                                           arabic_verse  \n",
       "2689            Ø£ÙÙ„ÙÙŠÙ’Ø³ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¨ÙØ£ÙØ­Ù’ÙƒÙÙ…Ù Ø§Ù„Ù’Ø­ÙØ§ÙƒÙÙ…ÙÙŠÙ†Ù  \n",
       "2690               Ø£ÙÙ„ÙÙ…Ù’ ÙŠÙØ¹Ù’Ù„ÙÙ…Ù’ Ø¨ÙØ£ÙÙ†Ù‘ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØ±ÙÙ‰Ù°  \n",
       "2691     Ø±ÙØ³ÙÙˆÙ„ÙŒ Ù…ÙÙ†ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙŠÙØªÙ’Ù„ÙÙˆ ØµÙØ­ÙÙÙ‹Ø§ Ù…ÙØ·ÙÙ‡Ù‘ÙØ±ÙØ©Ù‹  \n",
       "2692  ÙˆÙÙ…ÙØ§ Ø£ÙÙ…ÙØ±ÙÙˆØ§ Ø¥ÙÙ„Ù‘ÙØ§ Ù„ÙÙŠÙØ¹Ù’Ø¨ÙØ¯ÙÙˆØ§Ø§Ù„Ù„Ù‘ÙÙ‡ÙÙ…ÙØ®Ù’Ù„...  \n",
       "2693  Ø±ÙØ¶ÙÙŠÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ¹ÙÙ†Ù’Ù‡ÙÙ…Ù’ ÙˆÙØ±ÙØ¶ÙÙˆØ§ Ø¹ÙÙ†Ù’Ù‡Ù Ø°ÙÙ°Ù„ÙÙƒÙ ...  \n",
       "2694                           Ù†ÙØ§Ø±ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„Ù’Ù…ÙÙˆÙ‚ÙØ¯ÙØ©Ù  \n",
       "2695               Ø¥ÙØ°ÙØ§ Ø¬ÙØ§Ø¡Ù Ù†ÙØµÙ’Ø±ÙØ§Ù„Ù„Ù‘ÙÙ‡ÙÙˆÙØ§Ù„Ù’ÙÙØªÙ’Ø­Ù  \n",
       "2696  ÙˆÙØ±ÙØ£ÙÙŠÙ’ØªÙ Ø§Ù„Ù†Ù‘ÙØ§Ø³Ù ÙŠÙØ¯Ù’Ø®ÙÙ„ÙÙˆÙ†Ù ÙÙÙŠ Ø¯ÙÙŠÙ†ÙØ§Ù„Ù„Ù‘Ù...  \n",
       "2697                             Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙØ§Ù„Ù„Ù‘ÙÙ‡ÙØ£ÙØ­ÙØ¯ÙŒ  \n",
       "2698                                   Ø§Ù„Ù„Ù‘ÙÙ‡ÙØ§Ù„ØµÙ‘ÙÙ…ÙØ¯Ù  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    print(\"First 10 results:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nLast 10 results:\")\n",
    "    display(df.tail(10))\n",
    "else:\n",
    "    print(\"âš ï¸  No data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7b65c",
   "metadata": {
    "papermill": {
     "duration": 0.010338,
     "end_time": "2026-02-12T15:58:34.606177",
     "exception": false,
     "start_time": "2026-02-12T15:58:34.595839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "### âœ“ What This Notebook Does:\n",
    "1. **Scrapes** all 54 pages of Allah occurrences\n",
    "2. **Rejects** duplicate locations immediately (never adds them)\n",
    "3. **Reports** how many duplicates were rejected\n",
    "4. **Validates** the final dataset has zero duplicates\n",
    "5. **Saves** a clean CSV with exactly 2,699 unique entries\n",
    "\n",
    "### âœ“ Guarantees:\n",
    "- **Zero duplicates** in the final CSV file\n",
    "- **Exactly 2,699** unique location entries (or very close)\n",
    "- **No NameError** (os module imported)\n",
    "- **Transparent reporting** of what was rejected and why\n",
    "\n",
    "### âœ“ Philosophy:\n",
    "**Duplicates are REJECTED, not cleaned**\n",
    "- If we see a location twice, the second one is thrown away immediately\n",
    "- No duplicate ever makes it into `unique_results`\n",
    "- The validation step should always show zero duplicates\n",
    "- You get a clean dataset from the start, not a messy one that needs cleaning"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.827169,
   "end_time": "2026-02-12T15:58:35.237375",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-12T15:57:27.410206",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
