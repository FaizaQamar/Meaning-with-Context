{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a337cd25",
   "metadata": {
    "papermill": {
     "duration": 0.003937,
     "end_time": "2026-02-14T09:40:13.454244",
     "exception": false,
     "start_time": "2026-02-14T09:40:13.450307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ø§Ù„Ø±Ø­Ù…Ù† (Rahman) Scraper and CSV Updater\n",
    "\n",
    "This notebook:\n",
    "1. Scrapes all occurrences of \"Ø§Ù„Ø±Ø­Ù…Ù†\" (Rahman) from corpus.quran.com\n",
    "2. Processes the data to get frequency per verse and word locations\n",
    "3. Adds a new column \"rahman_frequency\" to the existing Quran CSV\n",
    "4. Adds a new column \"rahman_word_locations\" with the list of word positions\n",
    "\n",
    "**Data source:** https://corpus.quran.com/search.jsp?q=%D8%B1%D8%AD%D9%85%D8%A7%D9%86\n",
    "\n",
    "## âš ï¸ IMPORTANT: Internet Required\n",
    "This notebook requires internet access to scrape data from corpus.quran.com.\n",
    "\n",
    "**Run this notebook in:**\n",
    "- âœ… Kaggle (has internet access)\n",
    "- âœ… Google Colab (has internet access)\n",
    "- âœ… Your local Jupyter (if you have internet)\n",
    "- âŒ Claude.ai Computer Use (network disabled)\n",
    "\n",
    "## Features:\n",
    "- Rejects duplicates during scraping (not after)\n",
    "- Validates zero duplicates\n",
    "- Complete error handling\n",
    "- Progress tracking\n",
    "- Follows same pattern as your Allah scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5a1f8",
   "metadata": {
    "papermill": {
     "duration": 0.003045,
     "end_time": "2026-02-14T09:40:13.460333",
     "exception": false,
     "start_time": "2026-02-14T09:40:13.457288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7d43d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:13.467963Z",
     "iopub.status.busy": "2026-02-14T09:40:13.467598Z",
     "iopub.status.idle": "2026-02-14T09:40:18.795737Z",
     "shell.execute_reply": "2026-02-14T09:40:18.794489Z"
    },
    "papermill": {
     "duration": 5.334832,
     "end_time": "2026-02-14T09:40:18.798231",
     "exception": false,
     "start_time": "2026-02-14T09:40:13.463399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5505be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:18.808343Z",
     "iopub.status.busy": "2026-02-14T09:40:18.807760Z",
     "iopub.status.idle": "2026-02-14T09:40:20.493185Z",
     "shell.execute_reply": "2026-02-14T09:40:20.491924Z"
    },
    "papermill": {
     "duration": 1.692518,
     "end_time": "2026-02-14T09:40:20.495268",
     "exception": false,
     "start_time": "2026-02-14T09:40:18.802750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab5afe",
   "metadata": {
    "papermill": {
     "duration": 0.003362,
     "end_time": "2026-02-14T09:40:20.502199",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.498837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2: Define Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5348d76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:20.511141Z",
     "iopub.status.busy": "2026-02-14T09:40:20.510542Z",
     "iopub.status.idle": "2026-02-14T09:40:20.525147Z",
     "shell.execute_reply": "2026-02-14T09:40:20.524114Z"
    },
    "papermill": {
     "duration": 0.021729,
     "end_time": "2026-02-14T09:40:20.527203",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.505474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Scraping functions defined\n"
     ]
    }
   ],
   "source": [
    "def scrape_rahman_page(page_num, verbose=True):\n",
    "    \"\"\"\n",
    "    Scrape a single page of Rahman results from the Quranic corpus.\n",
    "    \n",
    "    Returns all results found on the page (duplicates handled by caller).\n",
    "    \"\"\"\n",
    "    url = f\"https://corpus.quran.com/search.jsp?q=%D8%B1%D8%AD%D9%85%D8%A7%D9%86&page={page_num}\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Scraping page {page_num}...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        if verbose:\n",
    "            print(\"âœ“\")\n",
    "    except requests.RequestException as e:\n",
    "        if verbose:\n",
    "            print(f\"âœ— Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    results = []\n",
    "    rows = soup.find_all('tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 3:\n",
    "            # Extract location (e.g., \"1:1:3\")\n",
    "            location_link = cells[0].find('a')\n",
    "            if location_link:\n",
    "                location = location_link.text.strip()\n",
    "                \n",
    "                # Parse location into chapter:verse:word_position\n",
    "                location_parts = location.split(':')\n",
    "                if len(location_parts) == 3:\n",
    "                    chapter = int(location_parts[0])\n",
    "                    verse = int(location_parts[1])\n",
    "                    word_position = int(location_parts[2])\n",
    "                    \n",
    "                    # Extract transliteration\n",
    "                    transliteration = cells[1].text.strip() if len(cells) > 1 else \"\"\n",
    "                    \n",
    "                    # Extract translation\n",
    "                    translation = cells[2].text.strip() if len(cells) > 2 else \"\"\n",
    "                    \n",
    "                    # Extract Arabic verse text\n",
    "                    arabic_verse = \"\"\n",
    "                    if len(cells) > 3:\n",
    "                        arabic_div = cells[3].find('div', class_='arabic')\n",
    "                        if arabic_div:\n",
    "                            arabic_verse = arabic_div.text.strip()\n",
    "                    \n",
    "                    results.append({\n",
    "                        'location': location,\n",
    "                        'chapter': chapter,\n",
    "                        'verse': verse,\n",
    "                        'word_position': word_position,\n",
    "                        'transliteration': transliteration,\n",
    "                        'translation': translation,\n",
    "                        'arabic_verse': arabic_verse\n",
    "                    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def scrape_all_rahman_pages(max_pages=20, delay=1.0):\n",
    "    \"\"\"\n",
    "    Scrape all pages of Rahman occurrences, rejecting duplicates immediately.\n",
    "    \n",
    "    Returns:\n",
    "    - unique_results: List of unique results\n",
    "    - rejected_count: Number of duplicates rejected\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Starting Rahman Scraping\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    seen_locations = set()\n",
    "    unique_results = []\n",
    "    rejected_count = 0\n",
    "    \n",
    "    for page_num in range(0, max_pages):\n",
    "        page_results = scrape_rahman_page(page_num)\n",
    "        \n",
    "        # If page returned no results, we've reached the end\n",
    "        if not page_results:\n",
    "            print(f\"\\nâœ“ Reached end of results at page {page_num}\")\n",
    "            break\n",
    "        \n",
    "        # Process each result, rejecting duplicates\n",
    "        for result in page_results:\n",
    "            location = result['location']\n",
    "            if location not in seen_locations:\n",
    "                seen_locations.add(location)\n",
    "                unique_results.append(result)\n",
    "            else:\n",
    "                rejected_count += 1\n",
    "        \n",
    "        # Respectful delay between requests\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Scraping Complete!\")\n",
    "    print(f\"  Total unique results: {len(unique_results)}\")\n",
    "    print(f\"  Duplicates rejected:  {rejected_count}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return unique_results, rejected_count\n",
    "\n",
    "\n",
    "print(\"âœ“ Scraping functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8484bb",
   "metadata": {
    "papermill": {
     "duration": 0.00321,
     "end_time": "2026-02-14T09:40:20.533982",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.530772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 3: Scrape All Rahman Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b5e5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:20.542148Z",
     "iopub.status.busy": "2026-02-14T09:40:20.541601Z",
     "iopub.status.idle": "2026-02-14T09:40:20.861239Z",
     "shell.execute_reply": "2026-02-14T09:40:20.860056Z"
    },
    "papermill": {
     "duration": 0.326202,
     "end_time": "2026-02-14T09:40:20.863332",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.537130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Starting Rahman Scraping\n",
      "======================================================================\n",
      "Scraping page 0... âœ“\n",
      "\n",
      "âœ“ Reached end of results at page 0\n",
      "\n",
      "======================================================================\n",
      "Scraping Complete!\n",
      "  Total unique results: 0\n",
      "  Duplicates rejected:  0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Scrape all Rahman occurrences\n",
    "rahman_results, rejected_count = scrape_all_rahman_pages(max_pages=20, delay=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fa25e",
   "metadata": {
    "papermill": {
     "duration": 0.003574,
     "end_time": "2026-02-14T09:40:20.870719",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.867145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 4: Create DataFrame and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b726cce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:20.879696Z",
     "iopub.status.busy": "2026-02-14T09:40:20.878859Z",
     "iopub.status.idle": "2026-02-14T09:40:20.919698Z",
     "shell.execute_reply": "2026-02-14T09:40:20.918725Z"
    },
    "papermill": {
     "duration": 0.047592,
     "end_time": "2026-02-14T09:40:20.921701",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.874109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame created with 0 rows\n",
      "Columns in scraped data: []\n",
      "\n",
      "First 10 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATION: Checking for duplicates\n",
      "======================================================================\n",
      "âœ“ PASS: Zero duplicates found in the dataset\n",
      "\n",
      "Last 10 results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "df_rahman = pd.DataFrame(rahman_results)\n",
    "\n",
    "print(f\"\\nDataFrame created with {len(df_rahman)} rows\")\n",
    "print(f\"Columns in scraped data: {list(df_rahman.columns)}\")\n",
    "\n",
    "# Display first few rows to see what we got\n",
    "print(\"\\nFirst 10 results:\")\n",
    "display(df_rahman.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VALIDATION: Checking for duplicates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for duplicate locations\n",
    "duplicate_locations = df_rahman[df_rahman.duplicated(subset=['location'], keep=False)]\n",
    "\n",
    "if len(duplicate_locations) == 0:\n",
    "    print(\"âœ“ PASS: Zero duplicates found in the dataset\")\n",
    "else:\n",
    "    print(f\"âœ— FAIL: {len(duplicate_locations)} duplicate entries found\")\n",
    "    print(\"\\nDuplicate locations:\")\n",
    "    display(duplicate_locations[['location', 'chapter', 'verse', 'word_position']].sort_values('location'))\n",
    "\n",
    "print(\"\\nLast 10 results:\")\n",
    "display(df_rahman.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64aeb86",
   "metadata": {
    "papermill": {
     "duration": 0.00391,
     "end_time": "2026-02-14T09:40:20.931331",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.927421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 5: Process Data to Get Frequency Per Verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8283fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:20.941162Z",
     "iopub.status.busy": "2026-02-14T09:40:20.940839Z",
     "iopub.status.idle": "2026-02-14T09:40:20.969255Z",
     "shell.execute_reply": "2026-02-14T09:40:20.968045Z"
    },
    "papermill": {
     "duration": 0.036213,
     "end_time": "2026-02-14T09:40:20.971398",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.935185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total surahs: 114\n",
      "Total verses in Quran: 6236\n",
      "\n",
      "Created complete verse structure with 6236 verses\n",
      "\n",
      "âš ï¸ WARNING: No Rahman data was scraped. Please check the scraping section.\n",
      "Creating empty Rahman columns...\n"
     ]
    }
   ],
   "source": [
    "# Define Quran structure (number of verses per surah)\n",
    "verses_per_surah = [\n",
    "    7, 286, 200, 176, 120, 165, 206, 75, 129, 109,\n",
    "    123, 111, 43, 52, 99, 128, 111, 110, 98, 135,\n",
    "    112, 78, 118, 64, 77, 227, 93, 88, 69, 60,\n",
    "    34, 30, 73, 54, 45, 83, 182, 88, 75, 85,\n",
    "    54, 53, 89, 59, 37, 35, 38, 29, 18, 45,\n",
    "    60, 49, 62, 55, 78, 96, 29, 22, 24, 13,\n",
    "    14, 11, 11, 18, 12, 12, 30, 52, 52, 44,\n",
    "    28, 28, 20, 56, 40, 31, 50, 40, 46, 42,\n",
    "    29, 19, 36, 25, 22, 17, 19, 26, 30, 20,\n",
    "    15, 21, 11, 8, 8, 19, 5, 8, 8, 11,\n",
    "    11, 8, 3, 9, 5, 4, 7, 3, 6, 3,\n",
    "    5, 4, 5, 6\n",
    "]\n",
    "\n",
    "print(f\"Total surahs: {len(verses_per_surah)}\")\n",
    "print(f\"Total verses in Quran: {sum(verses_per_surah)}\")\n",
    "\n",
    "# Create a complete list of all verses in the Quran\n",
    "all_verses = []\n",
    "for surah_num, num_verses in enumerate(verses_per_surah, start=1):\n",
    "    for verse_num in range(1, num_verses + 1):\n",
    "        all_verses.append({\n",
    "            'surah_no': surah_num,\n",
    "            'ayah_no': verse_num,\n",
    "            'rahman_frequency': 0,\n",
    "            'rahman_word_locations': []\n",
    "        })\n",
    "\n",
    "df_all_verses = pd.DataFrame(all_verses)\n",
    "print(f\"\\nCreated complete verse structure with {len(df_all_verses)} verses\")\n",
    "\n",
    "# Check if we have any Rahman data\n",
    "if len(df_rahman) == 0:\n",
    "    print(\"\\nâš ï¸ WARNING: No Rahman data was scraped. Please check the scraping section.\")\n",
    "    print(\"Creating empty Rahman columns...\")\n",
    "    df_rahman_complete = df_all_verses\n",
    "else:\n",
    "    # Make sure 'chapter' column exists (it should from scraping)\n",
    "    if 'chapter' not in df_rahman.columns:\n",
    "        print(\"\\nâœ— ERROR: 'chapter' column not found in scraped data\")\n",
    "        print(f\"Available columns: {list(df_rahman.columns)}\")\n",
    "        raise ValueError(\"Scraping did not produce expected columns\")\n",
    "    \n",
    "    # Group Rahman occurrences by verse and aggregate\n",
    "    rahman_by_verse = df_rahman.groupby(['chapter', 'verse']).agg({\n",
    "        'word_position': lambda x: sorted(list(x))  # List of word positions\n",
    "    }).reset_index()\n",
    "    \n",
    "    rahman_by_verse.columns = ['surah_no', 'ayah_no', 'rahman_word_locations']\n",
    "    rahman_by_verse['rahman_frequency'] = rahman_by_verse['rahman_word_locations'].apply(len)\n",
    "    \n",
    "    print(f\"\\nGrouped Rahman data by verse: {len(rahman_by_verse)} verses contain Rahman\")\n",
    "    \n",
    "    # Merge with complete verse list\n",
    "    df_rahman_complete = df_all_verses.merge(\n",
    "        rahman_by_verse,\n",
    "        on=['surah_no', 'ayah_no'],\n",
    "        how='left',\n",
    "        suffixes=('', '_rahman')\n",
    "    )\n",
    "    \n",
    "    # Update frequency and locations for verses that have Rahman\n",
    "    df_rahman_complete['rahman_frequency'] = df_rahman_complete['rahman_frequency_rahman'].fillna(\n",
    "        df_rahman_complete['rahman_frequency']\n",
    "    ).astype(int)\n",
    "    \n",
    "    df_rahman_complete['rahman_word_locations'] = df_rahman_complete.apply(\n",
    "        lambda row: row['rahman_word_locations_rahman'] if pd.notna(row['rahman_frequency_rahman']) else [],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    df_rahman_complete = df_rahman_complete[['surah_no', 'ayah_no', 'rahman_frequency', 'rahman_word_locations']]\n",
    "    \n",
    "    print(\"\\nProcessed Rahman frequency data:\")\n",
    "    print(f\"  Total verses: {len(df_rahman_complete)}\")\n",
    "    print(f\"  Verses with Rahman: {(df_rahman_complete['rahman_frequency'] > 0).sum()}\")\n",
    "    print(f\"  Verses without Rahman: {(df_rahman_complete['rahman_frequency'] == 0).sum()}\")\n",
    "    print(f\"  Total Rahman occurrences: {df_rahman_complete['rahman_frequency'].sum()}\")\n",
    "    \n",
    "    # Display sample verses with Rahman\n",
    "    print(\"\\nSample verses with Rahman:\")\n",
    "    display(df_rahman_complete[df_rahman_complete['rahman_frequency'] > 0].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a81c4",
   "metadata": {
    "papermill": {
     "duration": 0.00404,
     "end_time": "2026-02-14T09:40:20.979649",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.975609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 6: Load Existing CSV and Add Rahman Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1d67d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:20.989708Z",
     "iopub.status.busy": "2026-02-14T09:40:20.988949Z",
     "iopub.status.idle": "2026-02-14T09:40:21.118695Z",
     "shell.execute_reply": "2026-02-14T09:40:21.117785Z"
    },
    "papermill": {
     "duration": 0.137296,
     "end_time": "2026-02-14T09:40:21.120904",
     "exception": false,
     "start_time": "2026-02-14T09:40:20.983608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing CSV from: /kaggle/input/datasets/axha241419/proper-noun-word-allah-extracted/quran_ayahs_cleaned (3).csv\n",
      "\n",
      "Loaded 6236 rows\n",
      "Columns: ['serial_no', 'surah_no', 'ayah_no', 'ayah', 'frequency_proper_noun', 'label', 'length', 'tokens', 'word_count', 'word_locations_reordered']\n",
      "\n",
      "First 5 rows of existing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_no</th>\n",
       "      <th>surah_no</th>\n",
       "      <th>ayah_no</th>\n",
       "      <th>ayah</th>\n",
       "      <th>frequency_proper_noun</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_locations_reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø¨ÙØ³Û¡Ù…Ù Ù±Ù„Ù„Ù‘ÙÙ‡Ù Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>Ø¨ÙØ³Û¡Ù…Ù | Ù±Ù„Ù„Ù‘ÙÙ‡Ù | Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù | Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Ù±Ù„Û¡Ø­ÙÙ…Û¡Ø¯Ù Ù„ÙÙ„Ù‘ÙÙ‡Ù Ø±ÙØ¨Ù‘Ù Ù±Ù„Û¡Ø¹ÙÙ°Ù„ÙÙ…ÙÙŠÙ†Ù</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>Ù±Ù„Û¡Ø­ÙÙ…Û¡Ø¯Ù | Ù„ÙÙ„Ù‘ÙÙ‡Ù | Ø±ÙØ¨Ù‘Ù | Ù±Ù„Û¡Ø¹ÙÙ°Ù„ÙÙ…ÙÙŠÙ†Ù</td>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù | Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Ù…ÙÙ°Ù„ÙÙƒÙ ÙŠÙÙˆÛ¡Ù…Ù Ù±Ù„Ø¯Ù‘ÙÙŠÙ†Ù</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>Ù…ÙÙ°Ù„ÙÙƒÙ | ÙŠÙÙˆÛ¡Ù…Ù | Ù±Ù„Ø¯Ù‘ÙÙŠÙ†Ù</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Ø¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ¹Û¡Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ³Û¡ØªÙØ¹ÙÙŠÙ†Ù</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>Ø¥ÙÙŠÙ‘ÙØ§ÙƒÙ | Ù†ÙØ¹Û¡Ø¨ÙØ¯Ù | ÙˆÙØ¥ÙÙŠÙ‘ÙØ§ÙƒÙ | Ù†ÙØ³Û¡ØªÙØ¹ÙÙŠÙ†Ù</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_no  surah_no  ayah_no                                      ayah  \\\n",
       "0          1         1        1    Ø¨ÙØ³Û¡Ù…Ù Ù±Ù„Ù„Ù‘ÙÙ‡Ù Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù   \n",
       "1          2         1        2     Ù±Ù„Û¡Ø­ÙÙ…Û¡Ø¯Ù Ù„ÙÙ„Ù‘ÙÙ‡Ù Ø±ÙØ¨Ù‘Ù Ù±Ù„Û¡Ø¹ÙÙ°Ù„ÙÙ…ÙÙŠÙ†Ù   \n",
       "2          3         1        3                   Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù   \n",
       "3          4         1        4                   Ù…ÙÙ°Ù„ÙÙƒÙ ÙŠÙÙˆÛ¡Ù…Ù Ù±Ù„Ø¯Ù‘ÙÙŠÙ†Ù   \n",
       "4          5         1        5  Ø¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ¹Û¡Ø¨ÙØ¯Ù ÙˆÙØ¥ÙÙŠÙ‘ÙØ§ÙƒÙ Ù†ÙØ³Û¡ØªÙØ¹ÙÙŠÙ†Ù   \n",
       "\n",
       "   frequency_proper_noun  label  length  \\\n",
       "0                      1    NaN      38   \n",
       "1                      1    NaN      37   \n",
       "2                      0    NaN      23   \n",
       "3                      0    NaN      23   \n",
       "4                      0    NaN      40   \n",
       "\n",
       "                                           tokens  word_count  \\\n",
       "0    Ø¨ÙØ³Û¡Ù…Ù | Ù±Ù„Ù„Ù‘ÙÙ‡Ù | Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù | Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù           4   \n",
       "1     Ù±Ù„Û¡Ø­ÙÙ…Û¡Ø¯Ù | Ù„ÙÙ„Ù‘ÙÙ‡Ù | Ø±ÙØ¨Ù‘Ù | Ù±Ù„Û¡Ø¹ÙÙ°Ù„ÙÙ…ÙÙŠÙ†Ù           4   \n",
       "2                       Ù±Ù„Ø±Ù‘ÙØ­Û¡Ù…ÙÙ°Ù†Ù | Ù±Ù„Ø±Ù‘ÙØ­ÙÙŠÙ…Ù           2   \n",
       "3                     Ù…ÙÙ°Ù„ÙÙƒÙ | ÙŠÙÙˆÛ¡Ù…Ù | Ù±Ù„Ø¯Ù‘ÙÙŠÙ†Ù           3   \n",
       "4  Ø¥ÙÙŠÙ‘ÙØ§ÙƒÙ | Ù†ÙØ¹Û¡Ø¨ÙØ¯Ù | ÙˆÙØ¥ÙÙŠÙ‘ÙØ§ÙƒÙ | Ù†ÙØ³Û¡ØªÙØ¹ÙÙŠÙ†Ù           4   \n",
       "\n",
       "  word_locations_reordered  \n",
       "0                      [2]  \n",
       "1                      [2]  \n",
       "2                       []  \n",
       "3                       []  \n",
       "4                       []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the existing Quran CSV\n",
    "# âš ï¸ IMPORTANT: Update this path based on your environment\n",
    "\n",
    "# For Kaggle, if you uploaded the CSV as a dataset:\n",
    "# existing_csv_path = '/kaggle/input/your-dataset-name/quran_ayahs_cleaned__3___1_.csv'\n",
    "\n",
    "# For local Jupyter or Colab:\n",
    "existing_csv_path = '/kaggle/input/datasets/axha241419/proper-noun-word-allah-extracted/quran_ayahs_cleaned (3).csv'  # Update this path!\n",
    "\n",
    "print(f\"Loading existing CSV from: {existing_csv_path}\")\n",
    "df_quran = pd.read_csv(existing_csv_path)\n",
    "\n",
    "print(f\"\\nLoaded {len(df_quran)} rows\")\n",
    "print(f\"Columns: {list(df_quran.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of existing data:\")\n",
    "display(df_quran.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c013c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:21.131593Z",
     "iopub.status.busy": "2026-02-14T09:40:21.131229Z",
     "iopub.status.idle": "2026-02-14T09:40:21.162299Z",
     "shell.execute_reply": "2026-02-14T09:40:21.161287Z"
    },
    "papermill": {
     "duration": 0.038989,
     "end_time": "2026-02-14T09:40:21.164387",
     "exception": false,
     "start_time": "2026-02-14T09:40:21.125398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Rahman data with existing CSV...\n",
      "\n",
      "âœ“ Merge complete!\n",
      "  Total rows: 6236\n",
      "  New columns added: rahman_frequency, rahman_word_locations\n",
      "\n",
      "Verification:\n",
      "  Verses with Rahman: 0\n",
      "  Total Rahman occurrences: 0\n",
      "\n",
      "Sample verses with Rahman in updated CSV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_no</th>\n",
       "      <th>surah_no</th>\n",
       "      <th>ayah_no</th>\n",
       "      <th>ayah</th>\n",
       "      <th>rahman_frequency</th>\n",
       "      <th>rahman_word_locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [serial_no, surah_no, ayah_no, ayah, rahman_frequency, rahman_word_locations]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge Rahman data with existing CSV\n",
    "print(\"Merging Rahman data with existing CSV...\")\n",
    "\n",
    "df_updated = df_quran.merge(\n",
    "    df_rahman_complete,\n",
    "    on=['surah_no', 'ayah_no'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill any missing values with 0 frequency and empty list\n",
    "df_updated['rahman_frequency'] = df_updated['rahman_frequency'].fillna(0).astype(int)\n",
    "df_updated['rahman_word_locations'] = df_updated['rahman_word_locations'].apply(\n",
    "    lambda x: x if isinstance(x, list) else []\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Merge complete!\")\n",
    "print(f\"  Total rows: {len(df_updated)}\")\n",
    "print(f\"  New columns added: rahman_frequency, rahman_word_locations\")\n",
    "\n",
    "# Verify the merge\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"  Verses with Rahman: {(df_updated['rahman_frequency'] > 0).sum()}\")\n",
    "print(f\"  Total Rahman occurrences: {df_updated['rahman_frequency'].sum()}\")\n",
    "\n",
    "# Display sample verses with Rahman\n",
    "print(\"\\nSample verses with Rahman in updated CSV:\")\n",
    "display(df_updated[df_updated['rahman_frequency'] > 0][[\n",
    "    'serial_no', 'surah_no', 'ayah_no', 'ayah', \n",
    "    'rahman_frequency', 'rahman_word_locations'\n",
    "]].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ae455",
   "metadata": {
    "papermill": {
     "duration": 0.00436,
     "end_time": "2026-02-14T09:40:21.173358",
     "exception": false,
     "start_time": "2026-02-14T09:40:21.168998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 7: Save Updated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403a0e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:21.184931Z",
     "iopub.status.busy": "2026-02-14T09:40:21.184171Z",
     "iopub.status.idle": "2026-02-14T09:40:21.286855Z",
     "shell.execute_reply": "2026-02-14T09:40:21.285472Z"
    },
    "papermill": {
     "duration": 0.111545,
     "end_time": "2026-02-14T09:40:21.289341",
     "exception": false,
     "start_time": "2026-02-14T09:40:21.177796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving updated CSV to: quran_ayahs_with_rahman.csv\n",
      "\n",
      "======================================================================\n",
      "âœ“ SUCCESS! CSV updated and saved\n",
      "======================================================================\n",
      "\n",
      "Output file: quran_ayahs_with_rahman.csv\n",
      "Total rows: 6236\n",
      "Total columns: 12\n",
      "\n",
      "Columns in final CSV:\n",
      "  1. serial_no\n",
      "  2. surah_no\n",
      "  3. ayah_no\n",
      "  4. ayah\n",
      "  5. frequency_proper_noun\n",
      "  6. label\n",
      "  7. length\n",
      "  8. tokens\n",
      "  9. word_count\n",
      "  10. word_locations_reordered\n",
      "  11. rahman_frequency\n",
      "  12. rahman_word_locations\n",
      "\n",
      "ğŸ’¾ You can now download this file from your environment!\n"
     ]
    }
   ],
   "source": [
    "# Save the updated CSV\n",
    "# Output will be saved in the current working directory\n",
    "output_path = 'quran_ayahs_with_rahman.csv'\n",
    "\n",
    "print(f\"Saving updated CSV to: {output_path}\")\n",
    "df_updated.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ“ SUCCESS! CSV updated and saved\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nOutput file: {output_path}\")\n",
    "print(f\"Total rows: {len(df_updated)}\")\n",
    "print(f\"Total columns: {len(df_updated.columns)}\")\n",
    "print(f\"\\nColumns in final CSV:\")\n",
    "for i, col in enumerate(df_updated.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(\"\\nğŸ’¾ You can now download this file from your environment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852368f5",
   "metadata": {
    "papermill": {
     "duration": 0.004648,
     "end_time": "2026-02-14T09:40:21.299555",
     "exception": false,
     "start_time": "2026-02-14T09:40:21.294907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 8: Final Statistics and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6800bd55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T09:40:21.311094Z",
     "iopub.status.busy": "2026-02-14T09:40:21.310697Z",
     "iopub.status.idle": "2026-02-14T09:40:21.327889Z",
     "shell.execute_reply": "2026-02-14T09:40:21.326795Z"
    },
    "papermill": {
     "duration": 0.025393,
     "end_time": "2026-02-14T09:40:21.330036",
     "exception": false,
     "start_time": "2026-02-14T09:40:21.304643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Dataset Summary:\n",
      "  Total verses in Quran: 6236\n",
      "  Verses containing Rahman: 0\n",
      "  Verses without Rahman: 6236\n",
      "  Total Rahman occurrences: 0\n",
      "\n",
      "Rahman Frequency Distribution:\n",
      "\n",
      "======================================================================\n",
      "All steps completed successfully!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total verses in Quran: {len(df_updated)}\")\n",
    "print(f\"  Verses containing Rahman: {(df_updated['rahman_frequency'] > 0).sum()}\")\n",
    "print(f\"  Verses without Rahman: {(df_updated['rahman_frequency'] == 0).sum()}\")\n",
    "print(f\"  Total Rahman occurrences: {df_updated['rahman_frequency'].sum()}\")\n",
    "\n",
    "print(f\"\\nRahman Frequency Distribution:\")\n",
    "freq_dist = df_updated['rahman_frequency'].value_counts().sort_index()\n",
    "for freq, count in freq_dist.items():\n",
    "    if freq > 0:\n",
    "        print(f\"  {freq} occurrence(s): {count} verses\")\n",
    "\n",
    "# Find verses with multiple occurrences\n",
    "multiple_rahman = df_updated[df_updated['rahman_frequency'] > 1]\n",
    "if len(multiple_rahman) > 0:\n",
    "    print(f\"\\nVerses with multiple Rahman occurrences: {len(multiple_rahman)}\")\n",
    "    display(multiple_rahman[[\n",
    "        'surah_no', 'ayah_no', 'ayah', 'rahman_frequency', 'rahman_word_locations'\n",
    "    ]])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All steps completed successfully!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9488660,
     "sourceId": 14836264,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.938158,
   "end_time": "2026-02-14T09:40:21.956003",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-14T09:40:10.017845",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
