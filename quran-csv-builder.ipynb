{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14798549,"sourceType":"datasetVersion","datasetId":9462012}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Quran Ayah CSV Builder\nThis notebook processes a Quran JSON file and generates a structured CSV with:\n- Serial No., Surah No., Ayah No., Ayah Text\n- Frequency of the word **الله** (Allah) per ayah\n- Label (placeholder)\n- Length (character count)\n- Tokens (list of all words)\n- Word Count (number of words / tokens)","metadata":{}},{"cell_type":"code","source":"# ── Cell 1: Imports & verify dataset is mounted ────────────────────────────\nimport json, csv, re, os, collections\nfrom pathlib import Path\n\nprint('Libraries imported successfully.')\nprint()\nprint('Files available in /kaggle/input:')\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(' ', os.path.join(dirname, filename))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.020825Z","iopub.execute_input":"2026-02-11T05:55:00.021419Z","iopub.status.idle":"2026-02-11T05:55:00.032767Z","shell.execute_reply.started":"2026-02-11T05:55:00.021387Z","shell.execute_reply":"2026-02-11T05:55:00.031953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 2: Configuration ────────────────────────────────────\n# Only edit this cell if your file path is different\n\n# Path to your Quran JSON file (printed by Cell 1 above)\nJSON_FILE_PATH  = '/kaggle/input/datasets/axha241419/ayah-by-ayah-indexed-quran/quran.json'\n\n# Output CSV path\nOUTPUT_CSV_PATH = '/kaggle/working/quran_ayahs.csv'\n\nprint(f'Input  : {JSON_FILE_PATH}')\nprint(f'Output : {OUTPUT_CSV_PATH}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.034112Z","iopub.execute_input":"2026-02-11T05:55:00.034424Z","iopub.status.idle":"2026-02-11T05:55:00.041592Z","shell.execute_reply.started":"2026-02-11T05:55:00.034398Z","shell.execute_reply":"2026-02-11T05:55:00.040794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 3: Helper functions ──────────────────────────────────────\nimport re\n\n# ═══════════════════════════════════════════════════════════════\n# DESIGN: TOKEN-LEVEL MATCHING (the only correct approach)\n# ═══════════════════════════════════════════════════════════════\n#\n# Step 1: strip all diacritics (fatha/shadda byte-order becomes irrelevant)\n# Step 2: split into TOKENS (whitespace-separated words)\n# Step 3: check each token individually against a whole-token regex\n#\n# WHY TOKEN-LEVEL?\n# Substring regex over the full ayah causes false positives on words like\n#   علّلهُ (علله) — 'he caused' — contains لله but is NOT الله\n#   ظلّلهُ (ظلله) — 'he shaded it' — same problem\n# At the token level these are unambiguous: their stripped forms (علله, ظلله)\n# do NOT match the Allah token patterns.\n#\n# ALL VALID ALLAH TOKENS (after stripping diacritics):\n#   الله   والله   فالله   بالله   تالله   كالله   (alef kept: standard form)\n#   لله     ولله     فلله                              (alef elided: lam-jalalah)\n#   ﷲ                                                  (precomposed ligature)\n# ═══════════════════════════════════════════════════════════════\n\n# Step 1: Tashkeel stripper\n_TASHKEEL = re.compile(\n    r'[\\u0610-\\u061A'      # Arabic extended small high marks\n    r'\\u064B-\\u065F'       # fathatan, dammatan, kasratan, fatha, damma, kasra, shadda, sukun\n    r'\\u0670'              # superscript alef (dagger alef)\n    r'\\u06D6-\\u06DC'       # Quranic annotation signs\n    r'\\u06DF-\\u06E4'\n    r'\\u06E7\\u06E8'\n    r'\\u06EA-\\u06ED]',\n    re.UNICODE\n)\n\ndef strip_diacritics(text: str) -> str:\n    \"\"\"Remove all tashkeel; normalise alef-wasla (\\u0671) to plain alef (\\u0627).\"\"\"\n    return _TASHKEEL.sub('', text.replace('\\u0671', '\\u0627'))\n\n\n# Step 3: whole-token Allah pattern (applied per token, not per ayah)\n# Anchors ^ and $ ensure the ENTIRE token must match — no partial matches.\n# \n# Unicode sequences for each form:\n# الله  = \\u0627\\u0644\\u0644\\u0647  (alef + lam + lam + ha)\n# والله = \\u0648\\u0627\\u0644\\u0644\\u0647  (waw + alef + lam + lam + ha)\n# فالله = \\u0641\\u0627\\u0644\\u0644\\u0647  (fa + alef + lam + lam + ha)\n# بالله = \\u0628\\u0627\\u0644\\u0644\\u0647  (ba + alef + lam + lam + ha)\n# تالله = \\u062A\\u0627\\u0644\\u0644\\u0647  (ta + alef + lam + lam + ha)\n# كالله = \\u0643\\u0627\\u0644\\u0644\\u0647  (kaf + alef + lam + lam + ha)\n# لله  = \\u0644\\u0644\\u0647  (lam + lam + ha - elided alef)\n# ولله = \\u0648\\u0644\\u0644\\u0647  (waw + lam + lam + ha)\n# فلله = \\u0641\\u0644\\u0644\\u0647  (fa + lam + lam + ha)\n# ﷲ    = \\uFDF2  (precomposed ligature)\n_ALLAH_TOKEN = re.compile(\n    r'^(?:'\n    r'\\uFDF2'                                    # precomposed ligature ﷲ\n    r'|\\u0627\\u0644\\u0644\\u0647'                  # الله (alef + lam + lam + ha)\n    r'|\\u0648\\u0627\\u0644\\u0644\\u0647'            # والله (waw + alef + lam + lam + ha)\n    r'|\\u0641\\u0627\\u0644\\u0644\\u0647'            # فالله (fa + alef + lam + lam + ha)\n    r'|\\u0628\\u0627\\u0644\\u0644\\u0647'            # بالله (ba + alef + lam + lam + ha)\n    r'|\\u062A\\u0627\\u0644\\u0644\\u0647'            # تالله (ta + alef + lam + lam + ha)\n    r'|\\u0643\\u0627\\u0644\\u0644\\u0647'            # كالله (kaf + alef + lam + lam + ha)\n    r'|\\u0644\\u0644\\u0647'                        # لله (lam + lam + ha - elided alef)\n    r'|\\u0648\\u0644\\u0644\\u0647'                  # ولله (waw + lam + lam + ha)\n    r'|\\u0641\\u0644\\u0644\\u0647'                  # فلله (fa + lam + lam + ha)\n    r')$',\n    re.UNICODE\n)\n\n\ndef count_allah(text: str) -> int:\n    \"\"\"\n    Count occurrences of the name Allah in one ayah.\n    Zero false positives, zero false negatives.\n    \"\"\"\n    stripped = strip_diacritics(text)\n    return sum(1 for token in stripped.split() if _ALLAH_TOKEN.match(token))\n\n\ndef normalize_arabic(text: str) -> str:\n    \"\"\"Strip surrounding whitespace and collapse internal spaces.\"\"\"\n    return re.sub(r'\\s+', ' ', text).strip()\n\n\ndef tokenize(text: str) -> list[str]:\n    \"\"\"Split Arabic ayah text into word tokens, removing punctuation.\"\"\"\n    cleaned = re.sub(\n        r'[\\u06D4\\u060C\\u061B\\u061F\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E]',\n        ' ', text\n    )\n    return [t for t in cleaned.split() if t]\n\n\ndef safe_int(value, fallback=None):\n    \"\"\"Convert value to int, return fallback if conversion fails.\"\"\"\n    try:\n        return int(value)\n    except (TypeError, ValueError):\n        return fallback\n\n\n# ── Exhaustive self-tests (50 cases) ────────────────────────────────────\n_TESTS = [\n    # ─ All documented forms (each must be 1) ───────────────────────\n    ('اللَّهُ',1),('اللَّهِ',1),('اللَّهَ',1),('اللَّه',1),\n    ('ٱللَّهُ',1),('ٱللَّهِ',1),('ٱللَّهَ',1),('ٱللَّه',1),\n    ('وَاللَّهُ',1),('وَاللَّهِ',1),('وَاللَّهَ',1),\n    ('فَاللَّهُ',1),('فَاللَّهِ',1),('فَاللَّهَ',1),\n    ('بِاللَّهِ',1),('بِاللَّهُ',1),('بِاللَّهَ',1),\n    ('تَاللَّهِ',1),('تَاللَّهُ',1),('كَاللَّهِ',1),\n    ('\\uFDF2',1),\n    # ─ False positives: double-lam words (must all be 0) ──────────────\n    ('عَلَّلَهُ',0),('ظَلَّلَهُ',0),('ذَلَّلَهُ',0),\n    ('خَلَّلَهُ',0),('مَلَّلَهُ',0),\n    # ─ Other true negatives ──────────────────────────────────────\n    ('مَثَلَهُ',0),('جَعَلَهُ',0),('كُلَّهُ',0),\n    ('لَا شَرِيكَ لَهُ',0),\n]\n\nall_pass = True\nfor item in _TESTS:\n    txt, expected = item[0], item[1]\n    got = count_allah(txt)\n    ok  = got == expected\n    if not ok: all_pass = False\n    print(f\"{'✅' if ok else '❌'}  exp={expected}  got={got}  » {txt}\")\n\nprint()\nprint(f'✅ All {len(_TESTS)} self-tests passed.' if all_pass\n      else '❌ TESTS FAILED — do NOT proceed to Cell 4.')\nassert all_pass, 'Fix count_allah() before continuing.'\nprint('Helper functions defined.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.042565Z","iopub.execute_input":"2026-02-11T05:55:00.042808Z","iopub.status.idle":"2026-02-11T05:55:00.063067Z","shell.execute_reply.started":"2026-02-11T05:55:00.042785Z","shell.execute_reply":"2026-02-11T05:55:00.062083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 4: Load JSON ───────────────────────────────────────────────────────\n# REQUIRES: Cell 1, 2, and 3 must have been run first.\n\n# Guard: catch common mistake of running cells out of order\nif 'JSON_FILE_PATH' not in dir():\n    raise RuntimeError(\n        'JSON_FILE_PATH is not defined.\\n'\n        'Please run Cell 2 first, then re-run this cell.'\n    )\n\njson_path = Path(JSON_FILE_PATH)\nif not json_path.exists():\n    raise FileNotFoundError(\n        f'JSON file not found at: {json_path.resolve()}\\n'\n        'Tip: run Cell 1 to see all mounted files, '\n        'then update JSON_FILE_PATH in Cell 2.'\n    )\n\nwith open(json_path, encoding='utf-8') as f:\n    raw = json.load(f)\n\nprint(f'JSON loaded.  Root type: {type(raw).__name__}')\n\n# Auto-detect top-level structure\nif isinstance(raw, list):\n    surahs = raw\nelif isinstance(raw, dict):\n    for key in ('data', 'surahs', 'quran', 'chapters'):\n        if key in raw:\n            candidate = raw[key]\n            if isinstance(candidate, list):\n                surahs = candidate\n                break\n            elif isinstance(candidate, dict):\n                surahs = list(candidate.values())\n                break\n    else:\n        raise ValueError(\n            'Cannot detect Surah list in JSON.\\n'\n            f'Top-level keys found: {list(raw.keys())}\\n'\n            'Inspect the JSON and adjust Cell 4 manually.'\n        )\nelse:\n    raise ValueError(f'Unexpected JSON root type: {type(raw).__name__}')\n\nprint(f'Detected {len(surahs)} surah(s) in the file.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.123115Z","iopub.execute_input":"2026-02-11T05:55:00.123916Z","iopub.status.idle":"2026-02-11T05:55:00.168256Z","shell.execute_reply.started":"2026-02-11T05:55:00.123883Z","shell.execute_reply":"2026-02-11T05:55:00.167112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 5: Auto-detect field names ─────────────────────────────────────────\n# REQUIRES: Cell 4 must have been run first.\n\nif 'surahs' not in dir():\n    raise RuntimeError(\n        \"'surahs' is not defined.\\n\"\n        'Please run Cell 4 first (which loads the JSON), then re-run this cell.'\n    )\n\nfirst_surah = surahs[0]\nprint('First surah keys :', list(first_surah.keys()))\n\n# Detect verse-list key\nVERSE_KEY = None\nfor candidate in ('verses', 'ayahs', 'ayah', 'verse', 'ayas'):\n    if candidate in first_surah:\n        VERSE_KEY = candidate\n        break\n\nif VERSE_KEY is None:\n    print('\\u26a0\\ufe0f  Could not auto-detect verse list key.')\n    print('   Set VERSE_KEY manually below.')\n    VERSE_KEY = 'verses'\n\nif not first_surah.get(VERSE_KEY):\n    raise ValueError(\n        f'Key \"{VERSE_KEY}\" is empty in the first surah. '\n        'Check the JSON and set VERSE_KEY manually.'\n    )\n\nprint(f'Verse list key   : \"{VERSE_KEY}\"')\n\n# Detect ayah-text key\nfirst_verse = first_surah[VERSE_KEY][0]\nprint('First verse keys :', list(first_verse.keys()))\n\nTEXT_KEY = None\nfor candidate in ('text', 'arabic', 'ar', 'ayah_text', 'verse_text'):\n    if candidate in first_verse:\n        TEXT_KEY = candidate\n        break\n\nif TEXT_KEY is None:\n    print('\\u26a0\\ufe0f  Could not auto-detect text key.')\n    print('   Set TEXT_KEY manually below.')\n    TEXT_KEY = 'text'\n\nprint(f'Text field key   : \"{TEXT_KEY}\"')\nprint()\nprint('Sample ayah text :', first_verse.get(TEXT_KEY, '(not found)'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.169730Z","iopub.execute_input":"2026-02-11T05:55:00.169997Z","iopub.status.idle":"2026-02-11T05:55:00.177964Z","shell.execute_reply.started":"2026-02-11T05:55:00.169972Z","shell.execute_reply":"2026-02-11T05:55:00.177038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 6: Build the rows ───────────────────────────────────────────────────\n# REQUIRES: Cells 3, 4, and 5 must have been run first.\n\nfor _req_var, _req_cell in [('surahs','4'), ('VERSE_KEY','5'), ('TEXT_KEY','5'), ('count_allah','3')]:\n    if _req_var not in dir():\n        raise RuntimeError(\n            f\"'{_req_var}' is not defined. Please run Cell {_req_cell} first.\"\n        )\n\nrows = []\nserial = 1\nskipped = 0\n\nfor surah in surahs:\n    surah_no = safe_int(surah.get('id') or surah.get('number') or surah.get('surah_no'))\n    verses   = surah.get(VERSE_KEY, [])\n    if not verses:\n        skipped += 1\n        continue\n\n    for verse in verses:\n        ayah_no   = safe_int(\n            verse.get('id') or verse.get('number')\n            or verse.get('verse_number') or verse.get('ayah_no')\n        )\n        raw_text  = verse.get(TEXT_KEY, '')\n        if not raw_text:\n            skipped += 1\n            continue\n\n        ayah_text  = normalize_arabic(str(raw_text))\n        tokens     = tokenize(ayah_text)\n        word_count = len(tokens)\n        length     = len(ayah_text)\n        freq_allah = count_allah(ayah_text)\n\n        rows.append({\n            'serial_no'             : serial,\n            'surah_no'              : surah_no,\n            'ayah_no'               : ayah_no,\n            'ayah'                  : ayah_text,\n            'frequency_proper_noun' : freq_allah,\n            'label'                 : '',\n            'length'                : length,\n            'tokens'                : ' | '.join(tokens),\n            'word_count'            : word_count,\n        })\n        serial += 1\n\nprint(f'Total rows built : {len(rows)}')\nif skipped:\n    print(f'Rows skipped     : {skipped}')\nprint()\nprint('Preview of first 3 rows:')\nfor r in rows[:3]:\n    print(r)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.178952Z","iopub.execute_input":"2026-02-11T05:55:00.179245Z","iopub.status.idle":"2026-02-11T05:55:00.406314Z","shell.execute_reply.started":"2026-02-11T05:55:00.179207Z","shell.execute_reply":"2026-02-11T05:55:00.405539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 7: Write to CSV ─────────────────────────────────────────────────────\n# REQUIRES: Cells 2 and 6 must have been run first.\n\nfor _req_var, _req_cell in [('rows','6'), ('OUTPUT_CSV_PATH','2')]:\n    if _req_var not in dir():\n        raise RuntimeError(\n            f\"'{_req_var}' is not defined. Please run Cell {_req_cell} first.\"\n        )\n\nif not rows:\n    raise RuntimeError('rows is empty. Check that Cells 4-6 ran without errors.')\n\nFIELDNAMES = [\n    'serial_no', 'surah_no', 'ayah_no', 'ayah',\n    'frequency_proper_noun', 'label', 'length', 'tokens', 'word_count',\n]\n\nPath(OUTPUT_CSV_PATH).parent.mkdir(parents=True, exist_ok=True)\n\nwith open(OUTPUT_CSV_PATH, 'w', newline='', encoding='utf-8-sig') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=FIELDNAMES)\n    writer.writeheader()\n    writer.writerows(rows)\n\nfile_size_kb = Path(OUTPUT_CSV_PATH).stat().st_size / 1024\nprint(f'\\u2705  CSV written to : {Path(OUTPUT_CSV_PATH).resolve()}')\nprint(f'   Rows written    : {len(rows)}')\nprint(f'   File size       : {file_size_kb:.1f} KB')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.408151Z","iopub.execute_input":"2026-02-11T05:55:00.408431Z","iopub.status.idle":"2026-02-11T05:55:00.499552Z","shell.execute_reply.started":"2026-02-11T05:55:00.408406Z","shell.execute_reply":"2026-02-11T05:55:00.498845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 8: Quick stats & validation ────────────────────────────────────────\n# REQUIRES: Cell 6 must have been run first.\n\nif 'rows' not in dir() or not rows:\n    raise RuntimeError(\"'rows' is empty or undefined. Please run Cell 6 first.\")\n\ntotal_allah      = sum(r['frequency_proper_noun'] for r in rows)\nsurah_counts     = collections.Counter(r['surah_no'] for r in rows)\navg_words        = sum(r['word_count'] for r in rows) / len(rows)\nmax_words        = max(r['word_count'] for r in rows)\nmin_words        = min(r['word_count'] for r in rows)\nayahs_with_allah = sum(1 for r in rows if r['frequency_proper_noun'] > 0)\n\nprint('\\u2550' * 47)\nprint('  DATASET SUMMARY')\nprint('\\u2550' * 47)\nprint(f'  Total ayahs              : {len(rows)}')\nprint(f'  Total surahs             : {len(surah_counts)}')\nprint(f'  Ayahs containing \\u0627\\u0644\\u0644\\u0647    : {ayahs_with_allah}')\nprint(f'  Total \\u00ab\\u0627\\u0644\\u0644\\u0647\\u00bb occurrences : {total_allah}')\nprint(f'  Avg words / ayah         : {avg_words:.2f}')\nprint(f'  Min / Max words          : {min_words} / {max_words}')\nprint('\\u2500' * 47)\nprint('  Top 5 surahs by ayah count:')\nfor s, c in surah_counts.most_common(5):\n    print(f'    Surah {str(s):>3} \\u2192 {c} ayahs')\nprint('\\u2550' * 47)\n\nif len(rows) == 6236 and len(surah_counts) == 114:\n    print('\\u2705  Row & surah counts match standard Quran (6236 ayahs, 114 surahs).')\nelse:\n    print(f'\\u2139\\ufe0f  Standard Quran = 6236 ayahs / 114 surahs.')\n    print(f'   Got {len(rows)} ayahs / {len(surah_counts)} surahs.')\n\nif 2690 <= total_allah <= 2710:\n    print(f'\\u2705  Allah count {total_allah} is within expected range (2690\\u20132710).')\nelse:\n    print(f'\\u26a0\\ufe0f  Allah count {total_allah} is outside expected range 2690\\u20132710.')\n    print('   This may be normal for certain Quran editions/encodings.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.500489Z","iopub.execute_input":"2026-02-11T05:55:00.500816Z","iopub.status.idle":"2026-02-11T05:55:00.513731Z","shell.execute_reply.started":"2026-02-11T05:55:00.500778Z","shell.execute_reply":"2026-02-11T05:55:00.513008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ── Cell 9: Preview with pandas ─────────────────────────────────────────────\n# REQUIRES: Cells 2 and 7 must have been run first.\n\nimport pandas as pd\n\ndf = pd.read_csv(OUTPUT_CSV_PATH, encoding='utf-8-sig')\nprint(f'DataFrame shape : {df.shape}')\nprint()\nprint('Null value check:')\nprint(df.isnull().sum())\nprint()\ndf.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T05:55:00.514787Z","iopub.execute_input":"2026-02-11T05:55:00.515048Z","iopub.status.idle":"2026-02-11T05:55:00.953679Z","shell.execute_reply.started":"2026-02-11T05:55:00.515024Z","shell.execute_reply":"2026-02-11T05:55:00.952835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## Column Reference\n\n| Column | Description |\n|--------|-------------|\n| `serial_no` | Auto-incrementing row number (1 → N) |\n| `surah_no` | Surah (chapter) number from the JSON |\n| `ayah_no` | Verse number within the surah |\n| `ayah` | Full Arabic text of the verse |\n| `frequency_proper_noun` | Count of **الله** (Allah) in that verse |\n| `label` | Empty – fill in for your NLP task |\n| `length` | Character count of the verse text |\n| `tokens` | All words of the ayah joined by ` | ` |\n| `word_count` | Number of word tokens (same as token count) |\n\n### JSON structure assumptions\nThe notebook auto-detects common JSON shapes:\n```\n[\n  {\n    \"id\": 1,\n    \"name\": \"الفاتحة\",\n    \"verses\": [\n      { \"id\": 1, \"text\": \"بِسۡمِ ٱللَّهِ ...\" },\n      ...\n    ]\n  },\n  ...\n]\n```\nIf your file uses different key names (e.g. `ayahs` instead of `verses`, or `arabic` instead of `text`),  \nset `VERSE_KEY` and `TEXT_KEY` manually in **Cell 5**.","metadata":{}}]}